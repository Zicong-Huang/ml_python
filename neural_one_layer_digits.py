import pandas as pd
import numpy as np
import scipy.special as scsp
import matplotlib.pyplot as plt

from neural_get_train_and_valid import get_train_and_valid
from neural_one_vs_all_training import one_vs_all_training
from logistic_cost_function import logistic_cost_function
from neural_plot_digits import draw_random_gray_scale_digit
from neural_one_vs_all_pred import one_vs_all_predict

i_want_visual = input('Do you want visualization? [y/n]: ')
i_want_visual = (i_want_visual.strip().lower() == 'y')

'''Load data set'''
gray_scale_data = pd.read_csv('../ml_python/sample_data/MNIST.csv', header=None).to_numpy()
row, col = gray_scale_data.shape


'''Visualize the data'''
if i_want_visual:
    draw_random_gray_scale_digit(gray_scale_data)


'''Data partition'''
train_size_per_digit = 400
train_set, valid_set = get_train_and_valid(gray_scale_data, train_size_per_digit)

train_x = train_set[:, :col - 1]
train_y = train_set[:, col - 1]
train_y[train_y == 10] = 0

valid_x = valid_set[:, :col - 1]
valid_y = valid_set[:, col - 1]
valid_y[valid_y == 10] = 10


'''Test for logistic regression cost function'''
test_theta = np.zeros(train_x.shape[1])
test_cost = logistic_cost_function(test_theta, train_x, train_y)
print('test logistic cost function value:', test_cost, '\n')


'''One vs all training'''
input_or_calculate = input('Do you want to [1] input or [2] re-calculate the theta? [1/2]: ')
if input_or_calculate.strip() == '1':
    all_theta = pd.read_csv('../ml_python/sample_data/one_layer_neural_theta.csv', header=None).to_numpy()
else:
    all_theta = one_vs_all_training(train_x, train_y, lamb=0.1, num_iter=50)


'''One-layer activation'''
m = train_x.shape[0]
x = np.insert(train_x, 0, np.ones(m), axis=1)
z = x @ all_theta.T
activation = scsp.expit(z)


'''Visualizing one-layer activation'''
if i_want_visual:
    fig2, axs = plt.subplots(3, 3)
    for i in range(3):
        for j in range(3):
            x = np.random.randint(m)
            a = activation[x].reshape((5, 2))
            axs[i, j].imshow(a, cmap='gray')
            axs[i, j].get_xaxis().set_ticks([])
            axs[i, j].get_yaxis().set_ticks([])
            axs[i, j].set_xlabel(int(train_y[x]))
    fig2.suptitle("Example: One-layer activation")
    plt.pause(0.1)


'''Visualizing one-layer weights'''
if i_want_visual:
    fig3, axs = plt.subplots(2, 5)
    plot_theta = all_theta[:, 1:]
    for i in range(2):
        for j in range(5):
            pick = i*5 + j
            t = plot_theta[pick].reshape((20, 20))
            axs[i, j].imshow(t.T, cmap='gray')
            axs[i, j].get_xaxis().set_ticks([])
            axs[i, j].get_yaxis().set_ticks([])
            axs[i, j].set_xlabel(pick)
    fig3.suptitle("Example: One-layer weights")
    plt.pause(0.1)


'''Visualizing weighted pixels for one digit fitted different classifier'''
if i_want_visual:
    fig4, axs = plt.subplots(2, 5)
    plot_theta = all_theta[:, 1:]
    number = np.random.randint(10)                       # random number as an example
    example = np.random.randint(train_size_per_digit)    # random handwriting of the example number
    plot_train = train_x[train_y == number][example]
    for i in range(2):
        for j in range(5):
            pick = i*5 + j      # iterate through classifier 0 to 9
            plot_weighted = plot_train * plot_theta[pick]       # weighted pixel generated by different classifier
            t = plot_weighted.reshape((20, 20))
            weighted_sum = np.sum(t)
            weighted_sum_sigmoid = scsp.expit(weighted_sum)
            # the larger the weighted sum of pixels, the brighter
            axs[i, j].imshow(t.T, cmap='gray', vmin=0, vmax=1-weighted_sum_sigmoid)
            axs[i, j].get_xaxis().set_ticks([])
            axs[i, j].get_yaxis().set_ticks([])
            axs[i, j].set_xlabel(pick)
    title_txt = "Example: different classifier for one sample data: " + str(number)
    fig4.suptitle(title_txt)
    plt.pause(0.1)


'''In sample predicting'''
in_sample_pred = one_vs_all_predict(all_theta, train_x)
in_accuracy = np.sum(in_sample_pred == train_y)/len(in_sample_pred)
print('In sample accuracy:', '{percent:.2%}'.format(percent=in_accuracy))


'''Out sample predicting'''
out_sample_pred = one_vs_all_predict(all_theta, valid_x)
out_accuracy = np.sum(out_sample_pred == valid_y)/len(out_sample_pred)
print('Out sample accuracy:', '{percent:.2%}'.format(percent=out_accuracy))


'''output trained theta'''
save_text = input('Do you want to save the trained theta? [y/n]: ',)
if save_text.strip().lower() == 'y':
    np.savetxt('../ml_python/sample_data/one_layer_neural_theta.csv', all_theta, delimiter=',')
